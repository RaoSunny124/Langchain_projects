{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEd5PsrTasGwZIGzeWgPuC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaoSunny124/Langchain_projects/blob/main/Project_1_LangChain_Hello_World_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QESkn5iSWJhy"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('My_chatbot')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai -qU"
      ],
      "metadata": {
        "id": "gv5Rc_87WWHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "mdwsNlDKWxZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model= 'gemini-1.5-flash',\n",
        "                             api_key = gemini_api_key\n",
        "                             )"
      ],
      "metadata": {
        "id": "fEMj_sM_elLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_Template = PromptTemplate(\n",
        "    input_variable = ['question'],\n",
        "    template = 'Answer my all question when i asked question: \\n{question}'\n",
        ")"
      ],
      "metadata": {
        "id": "l_1SsEz2fQua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm = llm , prompt = prompt_Template)"
      ],
      "metadata": {
        "id": "ieTzFrVHhHiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is langchain?\"\n",
        "response = chain.run({\"question\" : question} )\n",
        "print(\"Answer:\", response)"
      ],
      "metadata": {
        "id": "-U45MJUbhjrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2400a654-a73e-4181-fb26-cd5703c95f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: LangChain is a framework for developing applications powered by large language models (LLMs).  It simplifies the process of building applications that leverage LLMs by providing tools and abstractions for:\n",
            "\n",
            "* **Modular components:** LangChain breaks down LLM application development into reusable components, such as chains, indexes, agents, and memory. This promotes modularity, making it easier to build, test, and maintain complex applications.\n",
            "\n",
            "* **Chain management:** Chains orchestrate the interaction between different components, allowing you to define complex workflows involving multiple LLMs or other tools.  This enables more sophisticated applications beyond simple prompt-response interactions.\n",
            "\n",
            "* **Memory:** LangChain provides mechanisms for LLMs to retain information across multiple interactions, enabling context-aware conversations and applications that require remembering previous exchanges.\n",
            "\n",
            "* **Agents:** Agents allow LLMs to interact with external resources (like APIs or databases) to gather information and perform actions beyond what's directly available in the prompt. This extends the capabilities of LLMs significantly.\n",
            "\n",
            "* **Index construction:** LangChain offers tools to index and query your own data, allowing you to build applications that use your specific knowledge base in conjunction with an LLM.\n",
            "\n",
            "In short, LangChain aims to make building LLM-powered applications easier, more efficient, and more robust by providing a structured and flexible framework for managing the different parts of such applications.  It handles the complexities of interacting with LLMs, allowing developers to focus on the application logic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6ZR1uSNQVDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}